# awesome-pruning-acceleration

Referred to [Awesome-Pruning](https://github.com/he-y/Awesome-Pruning)

## History

- [2019 years](#2019)
- [2018 years](#2018)
- [2017 years](#2017)
- [2016 years](#2016)
- [2015 years](#2015)

### 2019
|   Title  | Issue | Release |
| :--------| :---: | :-----: |

### 2018
|   Title  | Issue | Release |
| :--------| :---: | :-----: |
| [Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers](https://arxiv.org/abs/1802.00124) | ICLR | [GitHub](https://github.com/jack-willturner/batchnorm-pruning) |
| [Clustering Convolutional Kernels to Compress Deep Neural Networks](http://openaccess.thecvf.com/content_ECCV_2018/papers/Sanghyun_Son_Clustering_Kernels_for_ECCV_2018_paper.pdf) | ECCV | [GitHub](https://github.com/thstkdgus35/clustering-kernels) |
| [NISP: Pruning Networks using Neuron Importance Score Propagation](https://arxiv.org/abs/1711.05908) | CVPR | - |
| [Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks](https://arxiv.org/abs/1808.06866) | IJCAI | [GitHub](https://github.com/he-y/soft-filter-pruning) |

### 2017
|   Title  | Issue | Release |
| :--------| :---: | :-----: |
| [Pruning Filters for Efficient ConvNets](https://arxiv.org/abs/1608.08710) | ICLR | [GitHub](https://github.com/Eric-mingjie/rethinking-network-pruning/tree/master/imagenet/l1-norm-pruning) |
| [Pruning Convolutional Neural Networks for Resource Efficient Inference](https://arxiv.org/abs/1611.06440) | ICLR | [GitHub](https://github.com/Tencent/PocketFlow#channel-pruning) |
| [Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning](https://arxiv.org/abs/1611.05128) | CVPR | - |
| [ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression](http://openaccess.thecvf.com/content_ICCV_2017/papers/Luo_ThiNet_A_Filter_ICCV_2017_paper.pdf) | ICCV | [GitHub](https://github.com/Roll920/ThiNet) |
| [Channel pruning for accelerating very deep neural networks](https://arxiv.org/abs/1707.06168) | ICCV | [GitHub](https://github.com/yihui-he/channel-pruning) |
| [Learning Efficient Convolutional Networks Through Network Slimming](https://arxiv.org/abs/1708.06519) | ICCV | [GitHub](https://github.com/liuzhuang13/slimming) |
| [Scalpel: Customizing DNN Pruning to the Underlying Hardware Parallelism](https://ieeexplore.ieee.org/document/8192500) | ISCA | [GitHub](https://github.com/jiecaoyu/scalpel-1) |

### 2016
|   Title  | Issue | Release |
| :--------| :---: | :-----: |
| [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://arxiv.org/abs/1510.00149) | ICLR | - |
| [Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks](https://ieeexplore.ieee.org/abstract/document/7551407) | ISCA | - |

### 2015
|   Title  | Issue | Release |
| :--------| :---: | :-----: |
| [Learning both Weights and Connections for Efficient Neural Networks](https://arxiv.org/abs/1506.02626) | NIPS | - |
