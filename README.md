# awesome-pruning-acceleration [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
Hello visitors, I'm interested in architectural network reduction such as pruning, architectural search or decomposition tensors and also focus on leveraging network performance with knowledge distillation. This page is a historical summary for an extension of my working, pruning. If you have a quenstion for my working or any discussions with me, freely e-mail me (mincheol.park@kist.re.kr), Thanks !

## History

- [2019 years](#2019)
- [2018 years](#2018)
- [2017 years](#2017)
- [2016 years](#2016)
- [2015 years](#2015)

### 2019
|   Title  | Issue | Release |
| :--------| :---: | :-----: |
| [MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning](https://arxiv.org/abs/1903.10258) | ICCV | [GitHub](https://github.com/liuzechun/MetaPruning) |
| [Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration](https://arxiv.org/abs/1811.00250) | CVPR | [GitHub](https://github.com/he-y/filter-pruning-geometric-median) |
| [Network Pruning via Transformable Architecture Search](https://papers.nips.cc/paper/8364-network-pruning-via-transformable-architecture-search) | NIPS | [Github](https://github.com/D-X-Y/NAS-Projects) |
| [Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks](https://papers.nips.cc/paper/8486-gate-decorator-global-filter-pruning-method-for-accelerating-deep-convolutional-neural-networks) | NIPS | [Github](https://github.com/youzhonghui/gate-decorator-pruning) |
| [Integral Pruning on Activations and Weights for Efficient Neural Networks](https://openreview.net/forum?id=HyevnsCqtQ) | ICLR | - |
| [SNIP: Single-Shot Network Pruning Based on Connection Sensitivity](https://openreview.net/pdf?id=B1VZqjAcYX) | ICLR | - |

### 2018
|   Title  | Issue | Release |
| :--------| :---: | :-----: |
| [Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers](https://arxiv.org/abs/1802.00124) | ICLR | [GitHub](https://github.com/jack-willturner/batchnorm-pruning) |
| [Clustering Convolutional Kernels to Compress Deep Neural Networks](http://openaccess.thecvf.com/content_ECCV_2018/papers/Sanghyun_Son_Clustering_Kernels_for_ECCV_2018_paper.pdf) | ECCV | [GitHub](https://github.com/thstkdgus35/clustering-kernels) |
| [NISP: Pruning Networks using Neuron Importance Score Propagation](https://arxiv.org/abs/1711.05908) | CVPR | - |
| [Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks](https://arxiv.org/abs/1808.06866) | IJCAI | [GitHub](https://github.com/he-y/soft-filter-pruning) |

### 2017
|   Title  | Issue | Release |
| :--------| :---: | :-----: |
| [Pruning Filters for Efficient ConvNets](https://arxiv.org/abs/1608.08710) | ICLR | [GitHub](https://github.com/Eric-mingjie/rethinking-network-pruning/tree/master/imagenet/l1-norm-pruning) |
| [Pruning Convolutional Neural Networks for Resource Efficient Inference](https://arxiv.org/abs/1611.06440) | ICLR | [GitHub](https://github.com/Tencent/PocketFlow#channel-pruning) |
| [Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning](https://arxiv.org/abs/1611.05128) | CVPR | - |
| [ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression](http://openaccess.thecvf.com/content_ICCV_2017/papers/Luo_ThiNet_A_Filter_ICCV_2017_paper.pdf) | ICCV | [GitHub](https://github.com/Roll920/ThiNet) |
| [Channel pruning for accelerating very deep neural networks](https://arxiv.org/abs/1707.06168) | ICCV | [GitHub](https://github.com/yihui-he/channel-pruning) |
| [Learning Efficient Convolutional Networks Through Network Slimming](https://arxiv.org/abs/1708.06519) | ICCV | [GitHub](https://github.com/liuzhuang13/slimming) |
| [Scalpel: Customizing DNN Pruning to the Underlying Hardware Parallelism](https://ieeexplore.ieee.org/document/8192500) | ISCA | [GitHub](https://github.com/jiecaoyu/scalpel-1) |

### 2016
|   Title  | Issue | Release |
| :--------| :---: | :-----: |
| [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://arxiv.org/abs/1510.00149) | ICLR | - |
| [Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks](https://ieeexplore.ieee.org/abstract/document/7551407) | ISCA | - |

### 2015
|   Title  | Issue | Release |
| :--------| :---: | :-----: |
| [Learning both Weights and Connections for Efficient Neural Networks](https://arxiv.org/abs/1506.02626) | NIPS | - |
